{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sperm Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buraktango/2018-05-30-KRSCourseInBiomedicalImageAnalysisAndVisualization/blob/master/Sperm_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m6lK-mzWhES",
        "colab_type": "text"
      },
      "source": [
        "# Preparing Workspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo9kgUCGWxj8",
        "colab_type": "code",
        "outputId": "4d91ca82-a3dd-4ce3-da92-fb785e62c5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/My\\ Drive/Sperm_Classification"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Sperm_Classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOztBtx45hot",
        "colab_type": "text"
      },
      "source": [
        "# Reading Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94r_yuXm5pTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import remove_background\n",
        "\n",
        "text_file = open(\"SCIAN-MorphoSpermGS/PA-expert-annotations.txt\", 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aruDNCCcFj3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the text file\n",
        "lines = []\n",
        "for line in text_file.readlines():\n",
        "  lines.append(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXisALgwki8M",
        "colab_type": "text"
      },
      "source": [
        "**Separate the Images to their respective Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZFoBIFZkk_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoding = {0:\"Normal\",1:\"Tapered\",2:\"Pyriform\",3:\"Small\",5:\"Amorphous\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWzP4oRXWB7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "dataset_folder = \"DataSet\"\n",
        "folder_path = \"SCIAN-MorphoSpermGS/Partial-Agreement-Images\"\n",
        "\n",
        "for line in lines:\n",
        "  # p, pl, sample and sperm no.\n",
        "  x = line.split('-')\n",
        "  px = int(x[0][1:])\n",
        "  plx = int(x[1][2:])\n",
        "  samplex = int(x[2].split('/')[0][6:])\n",
        "  spermx  = int(x[2].split('/')[1].split('\\t')[0][6:])\n",
        "\n",
        "  # Annotation \n",
        "  label = int(line.split('\\t')[-1].split('\\n')[0])\n",
        "\n",
        "  img_file = f\"ch00_p{px}-pl{plx}-sample{samplex}-sperm{spermx}.tif\"\n",
        "\n",
        "  img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "  img = remove_background.remove_bg(img_path)\n",
        "\n",
        "  class_folder = os.path.join(dataset_folder, label_encoding[label])\n",
        "  img_file_write = f\"ch00_p{px}-pl{plx}-sample{samplex}-sperm{spermx}.png\"\n",
        "  img_write_path = os.path.join(class_folder, img_file_write)\n",
        "\n",
        "  cv2.imwrite(img_write_path, img)\n",
        "\n",
        "  print(f\"Writing: {img_file}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz0KTL6tpif2",
        "colab_type": "text"
      },
      "source": [
        "No of Samples per Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYQ9t-jupk6v",
        "colab_type": "code",
        "outputId": "d7d38be1-0f95-4c3c-b06d-bd486840181d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "dataset_folder = \"DataSet\"\n",
        "counts = {}\n",
        "for folder in os.listdir(dataset_folder):\n",
        "  counts[folder] = len(os.listdir(os.path.join(dataset_folder, folder)))\n",
        "  print(folder, len(os.listdir(os.path.join(dataset_folder, folder))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amorphous 656\n",
            "Normal 100\n",
            "Small 72\n",
            "Pyriform 76\n",
            "Tapered 228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL98mS5Kp3mE",
        "colab_type": "code",
        "outputId": "e9a694e0-6051-4a7c-9101-90c9b892ebb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "classes = counts.keys()\n",
        "values = counts.values()\n",
        "\n",
        "plt.bar(classes, values)\n",
        "#plt.savefig(\"plt.png\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jWQPsk3bLNm",
        "colab_type": "text"
      },
      "source": [
        "# Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUPOYMc5c_iG",
        "colab_type": "text"
      },
      "source": [
        "**Trainig with Custom Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rsX1MxubPaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def createCustomModel(input_shape, nClasses):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(input_shape=input_shape,filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=nClasses, activation=\"sigmoid\"))\n",
        "\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gra9ATSSbrIq",
        "colab_type": "text"
      },
      "source": [
        "**Train Test Split** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbrxhpmIbuE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def splitData(dataFolder, shape, batch_size):\n",
        "\n",
        "  data_dir = dataFolder\n",
        "  img_height = shape[0]\n",
        "  img_width = shape[1]\n",
        "\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      # shear_range=0.2,\n",
        "      # zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      validation_split=0.2) # set validation split\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      data_dir,\n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical',\n",
        "      subset='training') # set as training data\n",
        "\n",
        "  validation_generator = train_datagen.flow_from_directory(\n",
        "      data_dir, \n",
        "      target_size=(img_height, img_width),\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical',\n",
        "      subset='validation') # set as validation data\n",
        "\n",
        "  return train_generator, validation_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUmu8E2ScaCb",
        "colab_type": "text"
      },
      "source": [
        "**Compiling The Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCSGAuTgceSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "def compiling(model):\n",
        "  opt = SGD(lr=0.01, momentum=0.9, decay=0.01)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RERlWzschYH",
        "colab_type": "text"
      },
      "source": [
        "**Training The Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTKzafy6ckOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(model, train_generator, validation_generator, epoch, batch_size):\n",
        "  nb_epochs = epoch\n",
        "\n",
        "  model.fit_generator(\n",
        "      train_generator,\n",
        "      #steps_per_epoch = train_generator.samples // batch_size,\n",
        "      validation_data = validation_generator, \n",
        "      #validation_steps = validation_generator.samples // batch_size,\n",
        "      use_multiprocessing=True,\n",
        "      epochs = nb_epochs)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV6B0Z-Sr3Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def trainDataFolder(dataFolder, nClasses, shape, epoch, batch_size):\n",
        "  input_shape = (shape[0], shape[1], shape[2])\n",
        "\n",
        "  model = createCustomModel(input_shape, nClasses)\n",
        "  train_generator, validation_generator = splitData(dataFolder, shape, batch_size)\n",
        "  compiling(model)\n",
        "  print(\"Done\")\n",
        "  history = training(model, train_generator, validation_generator, epoch, batch_size)\n",
        "\n",
        "  return model, history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSXS-cvfriWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, history = trainDataFolder('DataSet', 5, (224,224,3), 10, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYkN9TcylhMd",
        "colab_type": "text"
      },
      "source": [
        "**Trainig with VGG and Xception Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sIbPRUtx4XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####### Using Xception prtrained model #########\n",
        "import keras\n",
        "from keras.applications.xception import Xception\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Input, Flatten, Dense, Dropout\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def createCustomModel(input_shape, nClasses):\n",
        "  #Get back the convolutional part of a VGG network trained on ImageNet\n",
        "  model_vgg16_conv = Xception(weights='imagenet', include_top=False)\n",
        "  model_vgg16_conv.summary()\n",
        "\n",
        "  #Create your own input format (here 3x200x200)\n",
        "  input = Input(shape=input_shape,name = 'image_input')\n",
        "\n",
        "  #Use the generated model \n",
        "  output_vgg16_conv = model_vgg16_conv(input)\n",
        "\n",
        "  #Add the fully-connected layers \n",
        "  x = Flatten(name='flatten')(output_vgg16_conv)\n",
        "  x = Dense(1024, activation='relu', name='fc1')(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Dense(nClasses, activation='softmax', name='predictions')(x)\n",
        "\n",
        "  #Create your own model \n",
        "  my_model = Model(input=input, output=x)\n",
        "\n",
        "  opt = SGD(lr=0.01, momentum=0.9, decay=0.01)\n",
        "\n",
        "  #In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
        "  #my_model.summary()\n",
        "  my_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return my_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzm-2d2EmEY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def trainXceptionModel(dataFolder, nClasses, shape, epoch, batch_size):\n",
        "  input_shape = (shape[0], shape[1], shape[2])\n",
        "\n",
        "  model = createCustomModel(input_shape, nClasses)\n",
        "  train_generator, validation_generator = splitData(dataFolder, shape, batch_size)\n",
        "  \n",
        "  history = training(model, train_generator, validation_generator, epoch, batch_size)\n",
        "\n",
        "  return model, history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-AVFUzkmblW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, history = trainXceptionModel('DataSet', 5, (224,224,3), 10, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFhpAwNvpbJK",
        "colab_type": "text"
      },
      "source": [
        "**Manual Reading of the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAM7fLHnCA4N",
        "colab_type": "code",
        "outputId": "4c621cd6-eff2-4b3d-a586-7cb597433916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import cv2\n",
        "# DataSet reading\n",
        "label_encoding = {0:\"Normal\",0:\"Tapered\",0:\"Pyriform\",0:\"Small\",1:\"Amorphous\"}\n",
        "label_decoding = {\"Normal\":0,\"Tapered\":0,\"Pyriform\":0,\"Small\":0,\"Amorphous\":1}\n",
        "\n",
        "data_folder = 'DataSet'\n",
        "Xtrain = []\n",
        "Ytrain = []\n",
        "\n",
        "Xtest = []\n",
        "Ytest = []\n",
        "\n",
        "for folder in os.listdir(data_folder):\n",
        "  print(f\"Reading {folder}\")\n",
        "  folder_path = os.path.join(data_folder, folder)\n",
        "  folder_images = os.listdir(folder_path)\n",
        "\n",
        "  folder_len = len(folder_images)\n",
        "  train_len = int(len(folder_images)*0.8)\n",
        "\n",
        "  # Collect Train images\n",
        "  for i in range(train_len):\n",
        "    img_file = os.path.join(folder_path, folder_images[i])\n",
        "    img = cv2.imread(img_file,0)\n",
        "\n",
        "    #print(img_file)\n",
        "    Xtrain.append(img)\n",
        "    Ytrain.append(label_decoding[str(folder)])\n",
        "\n",
        "  \n",
        "  # Collect Test images\n",
        "  for i in range(train_len, folder_len):\n",
        "    img_file = os.path.join(folder_path, folder_images[i])\n",
        "    img = cv2.imread(img_file,0)\n",
        "\n",
        "    Xtest.append(img)\n",
        "    Ytest.append(label_decoding[str(folder)])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading Amorphous\n",
            "Reading Normal\n",
            "Reading Small\n",
            "Reading Pyriform\n",
            "Reading Tapered\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggMg0QVt_sjN",
        "colab_type": "code",
        "outputId": "829d81de-8f6e-42cc-eda9-2d1e27ea1ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xtrain = np.array(Xtrain)\n",
        "Ytrain = np.array(Ytrain)\n",
        "\n",
        "Xtest = np.array(Xtest)\n",
        "Ytest = np.array(Ytest)\n",
        "\n",
        "Xtrain = np.expand_dims(Xtrain, axis=3)\n",
        "Xtest = np.expand_dims(Xtest, axis=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(903, 224, 224, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNkjXCC3H8zS",
        "colab_type": "code",
        "outputId": "88678d3f-4e1a-4e9f-e48a-5ee45ce7f51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "#Convert to Categorical\n",
        "n_classes = 5\n",
        "\n",
        "Ytrain = to_categorical(Ytrain, num_classes=n_classes)\n",
        "Ytest = to_categorical(Ytest, num_classes=n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N86SeRB6LFkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_model.fit(x=Xtrain, y=Ytrain, batch_size=16, epochs=10, validation_data=(Xtest, Ytest), use_multiprocessing=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}